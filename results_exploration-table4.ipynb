{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf537af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from natsort import natsorted\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385815a",
   "metadata": {},
   "source": [
    "#### Notebook Structure:\n",
    "\n",
    "The first 2 cells are just defining useful result formatting functions.\n",
    "\n",
    "Then, in the next non-empty cell we load in the results for each of the required datasets.\n",
    "\n",
    "Then, we extract the results for subsets of methods, starting with the U-Base (no update steps) and then allowing for various other combinations which can be specified by the user.\n",
    "\n",
    "Code in this notebook was used to generate Table 4 in the appendix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397049bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c23f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33ba6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "            \n",
    "def get_vars_method(method):\n",
    "\n",
    "    Q = np.zeros(10)\n",
    "    G = np.zeros(7)\n",
    "    U = np.zeros(8)\n",
    "    \n",
    "    first_name = method.split('_')[0]\n",
    "    second_name = method.split('_')[1]\n",
    "    try:\n",
    "        third_attr = method.split('_')[2]\n",
    "    except:\n",
    "        third_attr = 'missing'\n",
    "\n",
    "    try:\n",
    "        fourth_attr = method.split('_')[3]\n",
    "    except:\n",
    "       fourth_attr = 'missing'\n",
    "\n",
    "    try:\n",
    "        fifth_attr = method.split('_')[4]\n",
    "    except:\n",
    "        fifth_attr = 'missing'\n",
    "\n",
    "    try:\n",
    "        sixth_attr = method.split('_')[5]\n",
    "    except:\n",
    "        sixth_attr = 'missing'\n",
    "\n",
    "    try:\n",
    "        sev_attr = method.split('_')[6]\n",
    "    except:\n",
    "        sev_attr = 'missing'\n",
    "\n",
    "    try:\n",
    "        eight_attr = method.split('_')[7]\n",
    "    except:\n",
    "        eight_attr = 'missing'\n",
    "\n",
    "    Q_cat = 0.0\n",
    "    if first_name == 'cfr':\n",
    "        Q[0] = 1.0\n",
    "        Q_cat = 1\n",
    "    elif first_name == 'd':\n",
    "        Q[1] = 1.0\n",
    "        Q_cat = 2.0\n",
    "    elif first_name == 'dnotreg':\n",
    "        Q[2] = 1.0\n",
    "        Q_cat = 3.0\n",
    "    elif first_name == 'mn':\n",
    "        Q[3] = 1.0\n",
    "        Q_cat = 4.0\n",
    "    elif first_name == 'sl':\n",
    "        Q[4] = 1.0\n",
    "        Q_cat = 5.0\n",
    "    elif first_name == 'tvae':\n",
    "        Q[5] = 1.0\n",
    "        Q_cat = 6.0\n",
    "    elif first_name == 'lr':\n",
    "        Q[6] = 1.0\n",
    "        Q_cat = 7.0\n",
    "    elif first_name == 't':\n",
    "        Q[7] = 1.0\n",
    "        Q_cat = 8.0\n",
    "    elif first_name == 's':\n",
    "        Q[8] = 1.0\n",
    "        Q_cat = 9.0\n",
    "    elif first_name == 'dml':\n",
    "        Q[9] = 1\n",
    "        Q_cat = 10\n",
    "\n",
    "    if second_name == 'learner' or second_name == 'var':\n",
    "        second_name = third_attr\n",
    "    G_cat = 0.0\n",
    "    if second_name == 'dp':\n",
    "        G[1] = 1.0\n",
    "        G_cat = 2.0\n",
    "    elif second_name == 'mn':\n",
    "        G[3] = 1.0\n",
    "        G_cat = 4.0\n",
    "    elif second_name == 'dpnotreg':\n",
    "        G[2] = 1.0\n",
    "        G_cat = 3.0\n",
    "    elif second_name == 'cfr':\n",
    "        G[0] = 1.0\n",
    "        G_cat = 1.0\n",
    "    elif second_name == 'lr':\n",
    "        G[6] = 1.0\n",
    "        G_cat = 7.0\n",
    "    elif second_name == 'p':\n",
    "        G[5] = 1.0\n",
    "        G_cat = 6.0\n",
    "    elif second_name == 'sl':\n",
    "        G[4] = 1.0\n",
    "        G_cat = 5.0\n",
    "\n",
    "    U_cat = 0.0\n",
    "    if third_attr == 'missing' or  third_attr == 'var':\n",
    "        update_attr = 'Update: Base'\n",
    "\n",
    "    if fourth_attr == 'missing':\n",
    "        update_attr = 'Update: Base'\n",
    "\n",
    "    if fourth_attr == 'learner':\n",
    "        fourth_attr = fifth_attr\n",
    "        fifth_attr =  sixth_attr\n",
    "        sixth_attr = sev_attr\n",
    "        sev_attr = eight_attr\n",
    "\n",
    "    if fourth_attr == 'multi':\n",
    "        update_attr = 'Update: Multistep'\n",
    "    elif fourth_attr == 'submodel':\n",
    "        U[0] = 1.0\n",
    "        U_cat = 1.0\n",
    "    elif fourth_attr == 'onestep':\n",
    "        U[1] = 1.0\n",
    "        U_cat = 2.0\n",
    "\n",
    "    if fourth_attr == 'multi' and fifth_attr == 'nonlin' and sixth_attr == 'y' and sev_attr == 'var':\n",
    "        U[2] = 1.0\n",
    "        U_cat = 3.0\n",
    "    if fourth_attr == 'multi' and fifth_attr == 'nonlin' and sixth_attr == 'y' and sev_attr == 'meanvar':\n",
    "        U[3] = 1.0\n",
    "        U_cat = 4.0\n",
    "    if fourth_attr == 'multi' and fifth_attr == 'nonlin' and sixth_attr == 'noy' and sev_attr == 'var':\n",
    "        U[4] = 1.0\n",
    "        U_cat = 5.0\n",
    "    if fourth_attr == 'multi' and fifth_attr == 'nonlin' and sixth_attr == 'noy' and sev_attr == 'meanvar':\n",
    "        U[5] = 1.0\n",
    "        U_cat = 6.0\n",
    "\n",
    "    if fourth_attr == 'multi' and fifth_attr == 'linear' and sixth_attr == 'var':\n",
    "        U[6] = 1.0\n",
    "        U_cat = 7.0\n",
    "    if fourth_attr == 'multi' and fifth_attr == 'linear' and sixth_attr == 'meanvar':\n",
    "        U[7] = 1.0\n",
    "        U_cat = 8.0\n",
    "\n",
    "\n",
    "    cols_all = ['Q-CFR', 'Q-D', 'Q-Dnotreg', 'Q-MN', 'Q-SL', 'Q-TVAE', 'Q-LR', 'Q-T', 'Q-S', 'DML',\n",
    "           'G-CFR', 'G-D', 'G-Dnotreg', 'G-MN', 'G-SL', 'G-P', 'G-LR', 'U-sub', 'U-ones',\n",
    "           'U-multi-nonlin-fqh-var', 'U-multi-nonlin-fqh-meanvar', 'U-multi-nonlin-fh-var',\n",
    "           'U-multi-nonlin-fh-meanvar', 'U-multi-lin-var','U-multi-lin-meanvar']\n",
    "    cols_cat = ['QModel','GModel','UpdateStep']\n",
    "    QGU = np.concatenate([Q, G, U])\n",
    "    QGU_cat = np.concatenate([np.array([Q_cat]), np.array([G_cat]), np.array([U_cat])])\n",
    "\n",
    "    return QGU, QGU_cat, cols_all, cols_cat\n",
    "\n",
    "def rename_methods(method_names):\n",
    "    new_methods = []\n",
    "    for method in method_names:\n",
    "\n",
    "        first_name = method.split('_')[0]\n",
    "        second_name = method.split('_')[1]\n",
    "        try:\n",
    "            third_attr = method.split('_')[2]\n",
    "        except:\n",
    "            third_attr = 'missing'\n",
    "\n",
    "        try:\n",
    "            fourth_attr = method.split('_')[3]\n",
    "        except:\n",
    "           fourth_attr = 'missing'\n",
    "\n",
    "        try:\n",
    "            fifth_attr = method.split('_')[4]\n",
    "        except:\n",
    "            fifth_attr = 'missing'\n",
    "\n",
    "        try:\n",
    "            sixth_attr = method.split('_')[5]\n",
    "        except:\n",
    "            sixth_attr = 'missing'\n",
    "\n",
    "        try:\n",
    "            sev_attr = method.split('_')[6]\n",
    "        except:\n",
    "            sev_attr = 'missing'\n",
    "\n",
    "        try:\n",
    "            eight_attr = method.split('_')[7]\n",
    "        except:\n",
    "            eight_attr = 'missing'\n",
    "\n",
    "\n",
    "    #     print(' -' ,first_name, second_name, third_attr)\n",
    "        if first_name == 'cfr':\n",
    "            new_first_name = 'Q: CFR'\n",
    "        elif first_name == 'd':\n",
    "            new_first_name = 'Q: Dnet'\n",
    "        elif first_name == 'dnotreg':\n",
    "            new_first_name = 'Q: Dnet (no treg)'\n",
    "        elif first_name == 'mn':\n",
    "            new_first_name = 'Q: MN'\n",
    "        elif first_name == 'sl':\n",
    "            new_first_name = 'Q: SL'\n",
    "        elif first_name == 'tvae':\n",
    "            new_first_name = 'Q: TVAE'\n",
    "        elif first_name == 'lr':\n",
    "            new_first_name = 'Q: LR'\n",
    "        elif first_name == 't':\n",
    "            new_first_name = 'Q: T-learn'\n",
    "        elif first_name == 's':\n",
    "            new_first_name = 'Q: S-learn'\n",
    "\n",
    "        if second_name == 'learner' or second_name == 'var':\n",
    "            second_name = third_attr\n",
    "            \n",
    "        if second_name == 'dp':\n",
    "            new_second_name = 'G: Dnet'\n",
    "        elif second_name == 'mn':\n",
    "            new_second_name = 'G: MN'\n",
    "        elif second_name == 'dpnotreg':\n",
    "            new_second_name = 'G: Dnet (no treg)'\n",
    "        elif second_name == 'cfr':\n",
    "            new_second_name = 'G: CFR'\n",
    "        elif second_name == 'lr':\n",
    "            new_second_name = 'G: LR'\n",
    "        elif second_name == 'p':\n",
    "            new_second_name = 'G: P-Learn'\n",
    "        elif second_name == 'sl':\n",
    "            new_second_name = 'G: SL'\n",
    "\n",
    "        if third_attr == 'missing' or  third_attr == 'var':\n",
    "            new_second_name = ' '\n",
    "            update_attr = 'Update: Base'\n",
    "\n",
    "        if fourth_attr == 'missing':\n",
    "            update_attr = 'Update: Base'\n",
    "            new_second_name = ' '\n",
    "\n",
    "        if fourth_attr == 'learner':\n",
    "            fourth_attr = fifth_attr\n",
    "            fifth_attr =  sixth_attr\n",
    "            sixth_attr = sev_attr\n",
    "            sev_attr = eight_attr\n",
    "\n",
    "        if fourth_attr == 'multi':\n",
    "            update_attr = 'Update: Multistep'\n",
    "        elif fourth_attr == 'submodel':\n",
    "            update_attr = 'Update: Submodel'\n",
    "        elif fourth_attr == 'onestep':\n",
    "            update_attr = 'Update: Onestep'\n",
    "\n",
    "\n",
    "#         print('4th', fourth_attr, fifth_attr, sixth_attr, sev_attr, eight_attr)\n",
    "\n",
    "        if fourth_attr == 'multi' and fifth_attr == 'nonlin' and sixth_attr == 'y' and sev_attr == 'var':\n",
    "            update_attr = 'Update: Nonlinear Multistep f(Q,H) w/ var penalty'\n",
    "        if fourth_attr == 'multi' and fifth_attr == 'nonlin' and sixth_attr == 'y' and sev_attr == 'meanvar':\n",
    "            update_attr = 'Update: Nonlinear Multistep f(Q,H) w/ mean+var penalty'\n",
    "        if fourth_attr == 'multi' and fifth_attr == 'nonlin' and sixth_attr == 'noy' and sev_attr == 'var':\n",
    "            update_attr = 'Update: Nonlinear Multistep f(H) w/ var penalty'\n",
    "        if fourth_attr == 'multi' and fifth_attr == 'nonlin' and sixth_attr == 'noy' and sev_attr == 'meanvar':\n",
    "            update_attr = 'Update: Nonlinear Multistep f(H) w/ mean+var penalty'\n",
    "\n",
    "        if fourth_attr == 'multi' and fifth_attr == 'linear' and sixth_attr == 'var':\n",
    "            update_attr = 'Update: Linear Multistep w/ var penalty'\n",
    "        if fourth_attr == 'multi' and fifth_attr == 'linear' and sixth_attr == 'meanvar':\n",
    "            update_attr = 'Update: Linear Multistep w/ mean+var penalty'\n",
    "\n",
    "        new_name = new_first_name + ' ' + new_second_name + ' ' + update_attr\n",
    "        new_methods.append(new_name)\n",
    "    \n",
    "    return new_methods\n",
    "\n",
    "def get_files(folder, prefix):\n",
    "    all_files = os.listdir(folder)\n",
    "    files = []\n",
    "    for file in all_files:\n",
    "        if prefix in file:\n",
    "            files.append(file)\n",
    "    return natsorted(files)\n",
    "\n",
    "\n",
    "def get_results_dml(ds_prefix):\n",
    "    results_fn = 'results/'\n",
    "    data_fn = 'data/'\n",
    "    data_fs = get_files(data_fn, ds_prefix)\n",
    "    results_fs = get_files(results_fn, ds_prefix)\n",
    "\n",
    "    methods = []\n",
    "    for f in results_fs:\n",
    "        data = pd.read_csv('results/'  + f)\n",
    "        cols = set(data.columns)\n",
    "        cols.remove('measurement')\n",
    "        cols = list(cols)\n",
    "        methods = methods + cols\n",
    "\n",
    "    methods = set(['dml_learner', 'true_ate'])   \n",
    "    # collect into single dictionary\n",
    "    all_results_aeATE = {}\n",
    "    all_results_ATE = {}\n",
    "\n",
    "    for i in tqdm(range(len(results_fs))):\n",
    "        f = results_fs[i]\n",
    "        data = pd.read_csv(results_fn + f)\n",
    "        cols = data.columns\n",
    "        cols = set(data.columns)\n",
    "        cols.remove('measurement')\n",
    "        cols = list(cols)\n",
    "\n",
    "        for method in cols:\n",
    "\n",
    "            method_data = data[method]\n",
    "\n",
    "            try:            \n",
    "                all_results_aeATE[method].append(method_data.values[3])\n",
    "                all_results_ATE[method].append(method_data.values[2])\n",
    "            except:\n",
    "                all_results_aeATE[method] = []\n",
    "                all_results_ATE[method] = []\n",
    "\n",
    "                all_results_aeATE[method].append(method_data.values[3])\n",
    "                all_results_ATE[method].append(method_data.values[2])\n",
    "\n",
    "\n",
    "    all_results = {'aeATE': all_results_aeATE, 'ATE': all_results_ATE}\n",
    "\n",
    "    all_method_names = methods\n",
    "    all_method_names.remove('true_ate')\n",
    "\n",
    "    performance_results = {}\n",
    "    all_nan_methods = []\n",
    "    for method in tqdm(all_method_names):\n",
    "        method_results_dict = {}\n",
    "        # pull out relevant data\n",
    "        gt_ATE = all_results_aeATE['true_ate']\n",
    "        # the gt ATE gets stored twice (before and after update) so we only need every other value\n",
    "        gt_ATE = gt_ATE[::2]\n",
    "        method_results = all_results_ATE[method]\n",
    "        method_aeATEs = all_results_aeATE[method]\n",
    "        method_results_dict['aeate'] = np.asarray(method_aeATEs).mean()\n",
    "        method_results_dict['aeate_std'] = np.asarray(method_aeATEs).std()\n",
    "\n",
    "        method_results_dict['ate_std'] = np.asarray(method_results).std()\n",
    "        shapiro_test = stats.shapiro(method_results)\n",
    "        method_results_dict['all_ests'] = nanmean_(np.asarray(method_results))\n",
    "        method_results_dict['gt_ate'] = gt_ATE\n",
    "        method_results_dict['p'] = shapiro_test.pvalue\n",
    "        performance_results[method+'_var'] = method_results_dict\n",
    "        \n",
    "         # get rid of any nans\n",
    "        array_results = np.array(method_results)\n",
    "        to_remove = np.argwhere(np.isnan(array_results))\n",
    "\n",
    "        array_results = np.delete(array_results, to_remove)\n",
    "\n",
    "        temp_list = gt_ATE.copy()\n",
    "        for i in sorted(to_remove, reverse=True):\n",
    "            del temp_list[i[0]]\n",
    "        # now that nans are gone, get MSE\n",
    "        method_results_dict['mse'] = mean_squared_error(temp_list, array_results)\n",
    "        \n",
    "    return performance_results, all_results\n",
    "\n",
    "\n",
    "\n",
    "def get_results(ds_prefix):\n",
    "    results_fn = 'results/'\n",
    "    data_fn = 'data/'\n",
    "    data_fs = get_files(data_fn, ds_prefix)\n",
    "    results_fs = get_files(results_fn, ds_prefix)\n",
    "\n",
    "    methods = []\n",
    "    for f in results_fs:\n",
    "        data = pd.read_csv('results/'  + f)\n",
    "        cols = set(data.columns)\n",
    "        cols.remove('measurement')\n",
    "        cols = list(cols)\n",
    "        methods = methods + cols\n",
    "\n",
    "    methods = set(methods)   \n",
    "    # collect into single dictionary\n",
    "    all_results_aeATE = {}\n",
    "    all_results_ATE = {}\n",
    "\n",
    "    for i in tqdm(range(len(results_fs))):\n",
    "        f = results_fs[i]\n",
    "        data = pd.read_csv(results_fn + f)\n",
    "        cols = data.columns\n",
    "        cols = set(data.columns)\n",
    "        cols.remove('measurement')\n",
    "        cols = list(cols)\n",
    "\n",
    "        for method in cols:\n",
    "\n",
    "            method_data = data[method]\n",
    "\n",
    "            try:            \n",
    "                all_results_aeATE[method].append(method_data.values[3])\n",
    "                all_results_ATE[method].append(method_data.values[2])\n",
    "            except:\n",
    "                all_results_aeATE[method] = []\n",
    "                all_results_ATE[method] = []\n",
    "\n",
    "                all_results_aeATE[method].append(method_data.values[3])\n",
    "                all_results_ATE[method].append(method_data.values[2])\n",
    "\n",
    "\n",
    "    all_results = {'aeATE': all_results_aeATE, 'ATE': all_results_ATE}\n",
    "\n",
    "    all_method_names = methods\n",
    "    all_method_names.remove('true_ate')\n",
    "\n",
    "    performance_results = {}\n",
    "    all_nan_methods = []\n",
    "    for method in tqdm(all_method_names):\n",
    "        method_results_dict = {}\n",
    "        # pull out relevant data\n",
    "        gt_ATE = all_results_aeATE['true_ate']\n",
    "        # the gt ATE gets stored twice (before and after update) so we only need every other value\n",
    "        gt_ATE = gt_ATE[::2]\n",
    "        method_results = all_results_ATE[method]\n",
    "        method_aeATEs = all_results_aeATE[method]\n",
    "        method_results_dict['aeate'] = np.asarray(method_aeATEs).mean()\n",
    "        method_results_dict['aeate_std'] = np.asarray(method_aeATEs).std()\n",
    "\n",
    "        method_results_dict['ate_std'] = np.asarray(method_results).std()\n",
    "        shapiro_test = stats.shapiro(method_results)\n",
    "        method_results_dict['all_ests'] = nanmean_(np.asarray(method_results))\n",
    "        method_results_dict['gt_ate'] = gt_ATE\n",
    "        method_results_dict['p'] = shapiro_test.pvalue\n",
    "        performance_results[method+'_var'] = method_results_dict\n",
    "        \n",
    "         # get rid of any nans\n",
    "        array_results = np.array(method_results)\n",
    "        to_remove = np.argwhere(np.isnan(array_results))\n",
    "\n",
    "        array_results = np.delete(array_results, to_remove)\n",
    "\n",
    "        temp_list = gt_ATE.copy()\n",
    "        for i in sorted(to_remove, reverse=True):\n",
    "            del temp_list[i[0]]\n",
    "        # now that nans are gone, get MSE\n",
    "        method_results_dict['mse'] = mean_squared_error(temp_list, array_results)\n",
    "        \n",
    "    return performance_results, all_results\n",
    "\n",
    "def nanmean_(array):\n",
    "    nan_mean = np.nanmean(array)\n",
    "    inds = np.where(np.isnan(array))\n",
    "    array[inds] = nan_mean\n",
    "    return array\n",
    "\n",
    "def bootstrapper(gt, target, subsample_size=50, metric='mse'):\n",
    "    gt = np.asarray(gt)\n",
    "    indexes = np.arange(len(gt))\n",
    "    results = []\n",
    "    for i in range(5000):\n",
    "        index = np.random.choice(indexes, subsample_size)\n",
    "        gt_sample = gt[index]\n",
    "        target_sample = target[index]\n",
    "        if metric == 'mse':\n",
    "            results.append(mean_squared_error(gt_sample, target_sample))\n",
    "        elif metric == 'rmse':\n",
    "            results.append(mean_squared_error(gt_sample, target_sample, squared=False))\n",
    "        elif metric == 'mae':\n",
    "            results.append(mean_absolute_error(gt_sample, target_sample))\n",
    "            \n",
    "    results = np.asarray(results)\n",
    "    results_mean = results.mean()\n",
    "    results_std = results.std()\n",
    "    \n",
    "    return results_mean, results_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73300a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139474b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea63016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 224/224 [00:01<00:00, 114.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 514/514 [00:00<00:00, 3691.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 116.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 514/514 [00:00<00:00, 3727.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 117.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 514/514 [00:00<00:00, 3717.15it/s]\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "ds_prefix = 'RUN_all_general_TEST500_'\n",
    "performance, all_ds_results = get_results(ds_prefix)\n",
    "all_results['Gen n=500'] = performance\n",
    "\n",
    "ds_prefix = 'RUN_all_general_TEST5000_'\n",
    "performance, all_ds_results = get_results(ds_prefix)\n",
    "all_results['Gen n=5000'] = performance\n",
    "\n",
    "ds_prefix = 'RUN_all_general_TEST10000_'\n",
    "performance, all_ds_results = get_results(ds_prefix)\n",
    "all_results['Gen n=10000'] = performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0dcd3548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 112.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1387.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 111.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1959.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 109.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1813.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 202/202 [00:01<00:00, 105.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1754.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 112.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1735.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 108.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1536.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 198/198 [00:01<00:00, 110.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1718.98it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Just get DML results\n",
    "ds_prefix = 'RUN_all_synth1_TEST500_'\n",
    "performance, all_ds_results = get_results_dml(ds_prefix)\n",
    "all_results['LF (v1) n=500'] = performance\n",
    "\n",
    "ds_prefix = 'RUN_all_synth1_TEST5000_'\n",
    "performance, all_ds_results = get_results_dml(ds_prefix)\n",
    "all_results['LF (v1) n=5000'] = performance\n",
    "\n",
    "ds_prefix = 'RUN_all_synth1_TEST10000_'\n",
    "performance, all_ds_results = get_results_dml(ds_prefix)\n",
    "all_results['LF (v1) n=10000'] = performance\n",
    "\n",
    "\n",
    "ds_prefix = 'RUN_all_synth2_TEST500_'\n",
    "performance, all_ds_results = get_results_dml(ds_prefix)\n",
    "all_results['LF (v2) n=500'] = performance\n",
    "\n",
    "ds_prefix = 'RUN_all_synth2_TEST5000_'\n",
    "performance, all_ds_results = get_results_dml(ds_prefix)\n",
    "all_results['LF (v2) n=5000'] = performance\n",
    "\n",
    "ds_prefix = 'RUN_all_synth2_TEST10000_'\n",
    "performance, all_ds_results = get_results_dml(ds_prefix)\n",
    "all_results['LF (v2) n=10000'] = performance\n",
    "\n",
    "ds_prefix = 'RUN_all_IHDP_TEST500_'\n",
    "performance, all_ds_results = get_results_dml(ds_prefix)\n",
    "all_results['IHDP n=747'] = performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43541cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be205a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa23b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20f20ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_file = open(\"all_results_w_bootstraps_for_gen.pkl\", \"wb\")\n",
    "pickle.dump(all_results, a_file)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"all_results_w_bootstraps_for_gen.pkl\", \"rb\")\n",
    "all_results = pickle.load(a_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8b97e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dml_learner_var\n",
      "{'aeate': 0.06046927767998601, 'aeate_std': 0.04325641314074592, 'ate_std': 0.06397681939883436, 'all_ests': array([ 0.238233  ,  0.29326165,  0.1393417 ,  0.22584767,  0.27043374,\n",
      "        0.28217898,  0.2066498 ,  0.35716357,  0.29840365,  0.23868266,\n",
      "        0.24223313,  0.25779171,  0.30772401,  0.23357727,  0.29031597,\n",
      "        0.23848132,  0.25981547,  0.19550553,  0.27192651,  0.39703747,\n",
      "        0.24688382,  0.36265713,  0.17745281,  0.30242696,  0.16737587,\n",
      "        0.250966  ,  0.20106181,  0.26851178,  0.20629407,  0.32564568,\n",
      "        0.17066562,  0.12323202,  0.2962934 ,  0.10904111,  0.15264642,\n",
      "        0.28038225,  0.25622971,  0.35555172,  0.18777353,  0.17797524,\n",
      "        0.28709109,  0.30062898,  0.18672679,  0.22950613,  0.24241992,\n",
      "        0.26573144,  0.19603513, -0.00789397,  0.18237949,  0.27634963,\n",
      "        0.30402224,  0.21129611,  0.20942535,  0.31310883,  0.22230775,\n",
      "        0.26330043,  0.20895733,  0.30156978,  0.23979903,  0.19606871,\n",
      "        0.15631465,  0.17325397,  0.12133423,  0.25741435,  0.30432348,\n",
      "        0.2840374 ,  0.2927072 ,  0.21246825,  0.28805512,  0.30932179,\n",
      "        0.25476305,  0.20327679,  0.19976189,  0.3361599 ,  0.2420129 ,\n",
      "        0.36623257,  0.2034532 ,  0.20024443,  0.26960894,  0.32730835,\n",
      "        0.12442213,  0.2332666 ,  0.18280939,  0.25405268,  0.25308252,\n",
      "        0.24429217,  0.34106712,  0.23605593,  0.13462524,  0.25122361,\n",
      "        0.18943613,  0.27601407,  0.21442742,  0.26062227,  0.29614944,\n",
      "        0.20728331,  0.26760469,  0.18119151,  0.2299943 ,  0.28403278]), 'gt_ate': [0.226, 0.198, 0.188, 0.204, 0.142, 0.242, 0.228, 0.218, 0.23, 0.24, 0.216, 0.226, 0.216, 0.212, 0.214, 0.212, 0.17, 0.15, 0.188, 0.212, 0.228, 0.228, 0.154, 0.21, 0.168, 0.204, 0.196, 0.176, 0.244, 0.194, 0.17, 0.182, 0.21, 0.208, 0.156, 0.236, 0.208, 0.25, 0.196, 0.184, 0.206, 0.208, 0.15, 0.166, 0.206, 0.17, 0.196, 0.142, 0.224, 0.21, 0.228, 0.218, 0.154, 0.2, 0.162, 0.206, 0.15, 0.186, 0.23, 0.19, 0.204, 0.2, 0.128, 0.172, 0.23, 0.206, 0.204, 0.18, 0.18, 0.208, 0.182, 0.214, 0.166, 0.202, 0.204, 0.242, 0.146, 0.162, 0.166, 0.168, 0.164, 0.226, 0.172, 0.184, 0.212, 0.176, 0.19, 0.182, 0.148, 0.218, 0.138, 0.16, 0.22, 0.208, 0.16, 0.16, 0.154, 0.198, 0.204, 0.236], 'p': 0.12252876907587051, 'mse': 0.005527650820942155}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_527453/3417331725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_method\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mres_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mall_G_cols\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mall_U_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mU_base_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_star\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU_base_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# get extra results for DML comparison, starting with  U-base\n",
    "all_results_copy= all_results.copy()\n",
    "outcome_cols = ['p', 'mse', 'ate_std']\n",
    "ds_list = ['Gen n=500']\n",
    "\n",
    "for i in range(len(ds_list)):\n",
    "    dataset = [] \n",
    "    dataset_cat = []\n",
    "    ds = ds_list[i]\n",
    "    ds_var = np.array([i])\n",
    "\n",
    "    for method in all_results_copy[ds].keys():\n",
    "        result = all_results_copy[ds][method]\n",
    "\n",
    "        output_p, output_mse, output_ate_std  = np.asarray([result['p']]), np.asarray([result['mse']]), np.asarray([result['ate_std']])\n",
    "\n",
    "        var, var_cat, cols, cols_cat = get_vars_method(method)\n",
    "        cols += ['dataset'] + outcome_cols\n",
    "        cols_cat += ['dataset'] + outcome_cols\n",
    "        var = np.concatenate([var, ds_var, output_p, output_mse, output_ate_std])\n",
    "        var_cat = np.concatenate([var_cat, ds_var, output_p, output_mse, output_ate_std])\n",
    "        dataset.append(var)\n",
    "        dataset_cat.append(var_cat)\n",
    "\n",
    "        \n",
    "    dataset = pd.DataFrame(np.asarray(dataset), columns=cols)\n",
    "    dataset_cat = pd.DataFrame(np.asarray(dataset_cat), columns=cols_cat)\n",
    "    dataset = dataset.drop(columns=['U-multi-nonlin-fqh-var', 'U-multi-lin-var', 'U-multi-nonlin-fqh-meanvar', 'U-multi-nonlin-fh-var'])\n",
    "\n",
    "    Q_table = ['Q-MN','Q-SL','Q-TVAE','Q-T','DML']\n",
    "    G_table = [ 'G-SL', 'G-MN']\n",
    "    U_table = ['U-multi-lin-meanvar', 'U-sub']\n",
    "\n",
    "\n",
    "    all_Q_cols = [i for i in dataset.columns if 'Q-' in i]\n",
    "    all_Q_cols = all_Q_cols + ['DML']\n",
    "    all_G_cols = [i for i in dataset.columns if 'G-' in i]\n",
    "    all_U_cols = [i for i in dataset.columns if 'U-' in i]\n",
    "\n",
    "    desired_columns = Q_table + G_table + U_table + outcome_cols\n",
    "\n",
    "    result_columns = outcome_cols\n",
    "\n",
    "    U_base_results = []\n",
    "    method_names = []\n",
    "    for q_method in Q_table:    \n",
    "        temp_set = set(all_Q_cols).copy()\n",
    "        temp_set.remove(q_method)\n",
    "        result = dataset[(dataset[q_method] == 1)]\n",
    "        res_star = result[result[list(temp_set)+all_G_cols+all_U_cols].sum(1) == 0]\n",
    "        U_base_results.append(np.round(res_star[result_columns].values[0],4))\n",
    "\n",
    "    a = pd.DataFrame(U_base_results)\n",
    "    a.columns = outcome_cols\n",
    "    a.index = Q_table\n",
    "    display(HTML(a.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d49b8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>mse</th>\n",
       "      <th>ate_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q-MN</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-SL</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-TVAE</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-T</th>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>mse</th>\n",
       "      <th>ate_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q-MN</th>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-SL</th>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-TVAE</th>\n",
       "      <td>0.9806</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-T</th>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>mse</th>\n",
       "      <th>ate_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q-MN</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-SL</th>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-TVAE</th>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-T</th>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# get extra results  for DML comparison with other U-methods\n",
    "all_results_copy= all_results.copy()\n",
    "outcome_cols = ['p', 'mse', 'ate_std']\n",
    "ds_list = ['Gen n=500', 'Gen n=5000', 'Gen n=10000'] # 'LF (v2) n=10000' or  'Gen n=10000'\n",
    "ind_g = 'G-MN'\n",
    "ind_u = 'U-sub'\n",
    "\n",
    "for i in range(len(ds_list)):\n",
    "    dataset = [] \n",
    "    dataset_cat = []\n",
    "    ds = ds_list[i]\n",
    "    ds_var = np.array([i])\n",
    "\n",
    "    for method in all_results_copy[ds].keys():\n",
    "        result = all_results_copy[ds][method]\n",
    "        output_p, output_mse, output_atestd,  = np.asarray([result['p']]), np.asarray([result['mse']]), np.asarray([result['ate_std']])\n",
    "\n",
    "        var, var_cat, cols, cols_cat = get_vars_method(method)\n",
    "        cols += ['dataset'] + outcome_cols\n",
    "        cols_cat += ['dataset'] + outcome_cols\n",
    "        var = np.concatenate([var, ds_var, output_p, output_mse, output_atestd])\n",
    "        var_cat = np.concatenate([var_cat, ds_var, output_p, output_mse, output_atestd])\n",
    "        dataset.append(var)\n",
    "        dataset_cat.append(var_cat)\n",
    "\n",
    "\n",
    "\n",
    "    dataset = pd.DataFrame(np.asarray(dataset), columns=cols)\n",
    "    dataset_cat = pd.DataFrame(np.asarray(dataset_cat), columns=cols_cat)\n",
    "    dataset = dataset.drop(columns=['U-multi-nonlin-fqh-var', 'U-multi-lin-var', 'U-multi-nonlin-fqh-meanvar', 'U-multi-nonlin-fh-var'])\n",
    "\n",
    "\n",
    "    Q_table = ['Q-MN','Q-SL','Q-TVAE','Q-T','DML']\n",
    "    G_table = [ 'G-SL', 'G-MN']\n",
    "    U_table = ['U-multi-lin-meanvar', 'U-sub']\n",
    "\n",
    "\n",
    "    all_Q_cols = [i for i in dataset.columns if 'Q-' in i]\n",
    "    all_Q_cols = all_Q_cols + ['DML']\n",
    "    all_G_cols = [i for i in dataset.columns if 'G-' in i]\n",
    "    all_U_cols = [i for i in dataset.columns if 'U-' in i]\n",
    "\n",
    "    desired_columns = Q_table + G_table + U_table + ['p', 'aeate', 'ate_std']\n",
    "\n",
    "    result_columns = ['p', 'mse', 'ate_std']\n",
    "\n",
    "    method_names = []\n",
    "    reses = []\n",
    "    for q_method in Q_table[:-1]:\n",
    "\n",
    "        result = dataset[(dataset[q_method] == 1) &\n",
    "                        (dataset[ind_g] == 1 )&\n",
    "                        (dataset[ind_u] == 1)]\n",
    "\n",
    "        reses.append(np.round(result[result_columns].values[0],4))\n",
    "    a = pd.DataFrame(reses)\n",
    "#     print(ds, ind_g, ind_u)\n",
    "    a.columns = ['p', 'mse', 'ate_std']\n",
    "    a.index = Q_table[:-1]\n",
    "    display(HTML(a.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e40a937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.92605487e-09] [0.01288847] [0.44079598]\n"
     ]
    }
   ],
   "source": [
    "# just DML:\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# get extra results for DML comparison, starting with  U-base\n",
    "all_results_copy= all_results.copy()\n",
    "outcome_cols = ['p', 'mse', 'ate_std']\n",
    "ds_list = ['IHDP n=747']\n",
    "\n",
    "for i in range(len(ds_list)):\n",
    "    dataset = [] \n",
    "    dataset_cat = []\n",
    "    ds = ds_list[i]\n",
    "    ds_var = np.array([i])\n",
    "\n",
    "\n",
    "    result = all_results_copy[ds]['dml_learner_var']\n",
    "\n",
    "    output_p, output_mse, output_ate_std  = np.asarray([result['p']]), np.asarray([result['mse']]), np.asarray([result['ate_std']])\n",
    "\n",
    "    print(output_p, output_mse, output_ate_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2c0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06215f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9893b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b64a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1616e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
